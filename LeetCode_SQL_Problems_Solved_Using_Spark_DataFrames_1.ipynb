{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTG51mfe16hd",
        "outputId": "66cc40d5-8576-4ba9-89c4-e0062fe91c20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=5526f32574a4e9fc86e0949ba17960980f5b8e6f1890d1ddb55131e5397cd31e\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "DF_KlVk519aM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "ysJgibv2Ddb4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"LeetcodeEasySQLProblemsPartOne\").getOrCreate()"
      ],
      "metadata": {
        "id": "eTRXHvv_2v5L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PROBLEM 1\n",
        "https://leetcode.com/problems/combine-two-tables/\n",
        "\n",
        "# Objective:\n",
        "Learn to do a Basic Left Join in spark\n",
        "\n",
        "\n",
        "```\n",
        "Table: Person\n",
        "\n",
        "+-------------+---------+\n",
        "| Column Name | Type    |\n",
        "+-------------+---------+\n",
        "| personId    | int     |\n",
        "| lastName    | varchar |\n",
        "| firstName   | varchar |\n",
        "+-------------+---------+\n",
        "personId is the primary key (column with unique values) for this table.\n",
        "This table contains information about the ID of some persons and their first and last names.\n",
        "\n",
        "\n",
        "Table: Address\n",
        "\n",
        "+-------------+---------+\n",
        "| Column Name | Type    |\n",
        "+-------------+---------+\n",
        "| addressId   | int     |\n",
        "| personId    | int     |\n",
        "| city        | varchar |\n",
        "| state       | varchar |\n",
        "+-------------+---------+\n",
        "addressId is the primary key (column with unique values) for this table.\n",
        "Each row of this table contains information about the city and state of one person with ID = PersonId.\n",
        "\n",
        "\n",
        "Write a solution to report the first name, last name, city, and state of each person in the Person table. If the address of a personId is not present in the Address table, report null instead.\n",
        "\n",
        "Return the result table in any order.\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lmOOQN4a3Rj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "person_data = [\n",
        "    {'personId': 1, 'firstName': 'Allen', 'lastName': 'Wang'},\n",
        "    {'personId': 2, 'firstName': 'Alice', 'lastName': 'Bob'},\n",
        "]\n",
        "person_df = spark.createDataFrame(person_data)"
      ],
      "metadata": {
        "id": "nks-337q3VcR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "person_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDm9SrFY4eJq",
        "outputId": "5fce035e-4106-4960-985c-9a687dbaa2ee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+--------+\n",
            "|firstName|lastName|personId|\n",
            "+---------+--------+--------+\n",
            "|    Allen|    Wang|       1|\n",
            "|    Alice|     Bob|       2|\n",
            "+---------+--------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WAP4KnL17xdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "address_data = [\n",
        "    {'addressId':1, 'personId':2,  'city': 'New York City',  'state': 'New York'},\n",
        "    {'addressId':2, 'personId':3,  'city': 'Leetcode',  'state': 'California'}\n",
        "]\n",
        "address_df = spark.createDataFrame(address_data)"
      ],
      "metadata": {
        "id": "PMJnElrB5GLQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "person_df.join(address_df, person_df[\"personId\"] == address_df[\"personID\"], \"left\").select(\"firstName\", \"lastName\", \"city\", \"state\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nwcSmom535o",
        "outputId": "a729a125-4a8d-43af-bfdc-858c8f87efe0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+-------------+--------+\n",
            "|firstName|lastName|         city|   state|\n",
            "+---------+--------+-------------+--------+\n",
            "|    Allen|    Wang|         NULL|    NULL|\n",
            "|    Alice|     Bob|New York City|New York|\n",
            "+---------+--------+-------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Ubbz60B7Bu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2\n",
        "https://leetcode.com/problems/employees-earning-more-than-their-managers/\n",
        "\n",
        "# Objective\n",
        "Do a self join in spark and filter\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Table: Employee\n",
        "\n",
        "+-------------+---------+\n",
        "| Column Name | Type    |\n",
        "+-------------+---------+\n",
        "| id          | int     |\n",
        "| name        | varchar |\n",
        "| salary      | int     |\n",
        "| managerId   | int     |\n",
        "+-------------+---------+\n",
        "id is the primary key (column with unique values) for this table.\n",
        "Each row of this table indicates the ID of an employee, their name, salary, and the ID of their manager.\n",
        "\n",
        "\n",
        "Write a solution to find the employees who earn more than their managers.\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YE_dxuSD7yzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employee_data = [\n",
        "    {'id': 1, 'name': 'Joe', 'salary': 70000, 'managerId': 3},\n",
        "    {'id': 2, 'name': 'Henry', 'salary': 80000, 'managerId': 4},\n",
        "    {'id': 3, 'name': 'Sam', 'salary': 60000, 'managerId': None},\n",
        "    {'id': 4, 'name': 'Max', 'salary': 90000, 'managerId': None}\n",
        "]"
      ],
      "metadata": {
        "id": "GQFMa8j475bf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employee_df = spark.createDataFrame(employee_data)\n",
        "employee_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEVdT_sm9MeD",
        "outputId": "e3a811e7-b6cc-43d5-8f08-3f96684a4684"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+-----+------+\n",
            "| id|managerId| name|salary|\n",
            "+---+---------+-----+------+\n",
            "|  1|        3|  Joe| 70000|\n",
            "|  2|        4|Henry| 80000|\n",
            "|  3|     NULL|  Sam| 60000|\n",
            "|  4|     NULL|  Max| 90000|\n",
            "+---+---------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "employee_df.alias(\"emp1\").join(employee_df.alias(\"emp2\"), col(\"emp1.managerId\") == col(\"emp2.id\"), \"left\").filter(col(\"emp1.salary\") > col(\"emp2.salary\")).select(\n",
        "    col(\"emp1.name\"), col(\"emp1.salary\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTDnx-nR9S4b",
        "outputId": "7e946648-8610-4c3d-e076-64c7c8e6500a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+\n",
            "|name|salary|\n",
            "+----+------+\n",
            "| Joe| 70000|\n",
            "+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W75QSdPT9_pX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3\n",
        "\n",
        "https://leetcode.com/problems/game-play-analysis-ii/\n",
        "\n",
        "# Objective\n",
        "Apply a window function(rank) and filter by it\n",
        "\n",
        "\n",
        "```\n",
        "Table: Activity\n",
        "\n",
        "+--------------+---------+\n",
        "| Column Name  | Type    |\n",
        "+--------------+---------+\n",
        "| player_id    | int     |\n",
        "| device_id    | int     |\n",
        "| event_date   | date    |\n",
        "| games_played | int     |\n",
        "+--------------+---------+\n",
        "(player_id, event_date) is the primary key (combination of columns with unique values) of this table.\n",
        "This table shows the activity of players of some games.\n",
        "Each row is a record of a player who logged in and played a number of games (possibly 0)\n",
        "before logging out on someday using some device.\n",
        "\n",
        "\n",
        "Write a solution to report the device that is first logged in for\n",
        "each player\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "dTF7J2NNCQPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "activity_data = [\n",
        "     {'player_id':1, 'device_id':2, 'event_date':datetime(year=2016, month=3, day=1), 'games_played':5},\n",
        "     {'player_id':1, 'device_id':2, 'event_date':datetime(year=2016, month=5, day=2), 'games_played':6},\n",
        "     {'player_id':2, 'device_id':3, 'event_date':datetime(year=2017, month=6, day=25), 'games_played':1},\n",
        "     {'player_id':3, 'device_id':1, 'event_date':datetime(year=2016, month=3, day=2), 'games_played':0},\n",
        "     {'player_id':3, 'device_id':4, 'event_date':datetime(year=2018, month=7, day=3), 'games_played':5}\n",
        "]\n",
        "activity_df = spark.createDataFrame(activity_data)\n",
        "activity_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfMpOVTKCS60",
        "outputId": "a4a4f603-616a-461d-e58f-be219b8d4ce5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------+------------+---------+\n",
            "|device_id|         event_date|games_played|player_id|\n",
            "+---------+-------------------+------------+---------+\n",
            "|        2|2016-03-01 00:00:00|           5|        1|\n",
            "|        2|2016-05-02 00:00:00|           6|        1|\n",
            "|        3|2017-06-25 00:00:00|           1|        2|\n",
            "|        1|2016-03-02 00:00:00|           0|        3|\n",
            "|        4|2018-07-03 00:00:00|           5|        3|\n",
            "+---------+-------------------+------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank, desc"
      ],
      "metadata": {
        "id": "PUjZGHEtF3yF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_specs = Window.partitionBy(\"player_id\").orderBy(\"event_date\")\n",
        "activity_df.withColumn(\"rnk\", rank().over(window_specs)).filter(col(\"rnk\") == 1).select(\"player_id\", \"device_id\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maGXor_EGdCI",
        "outputId": "f675c1fd-2cbd-47eb-efbf-960a59a12447"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+\n",
            "|player_id|device_id|\n",
            "+---------+---------+\n",
            "|        1|        2|\n",
            "|        2|        3|\n",
            "|        3|        1|\n",
            "+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AzxPQ47tHfgs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}